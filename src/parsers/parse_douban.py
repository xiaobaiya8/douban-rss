import json
import requests
from bs4 import BeautifulSoup
import time
import os
import re
import random
import traceback
# å¯¼å…¥è±†ç“£å·¥å…·æ¨¡å—
from src.utils.douban_utils import extract_subject_id, load_config, check_cookie_valid, send_telegram_message, send_wecom_message, make_douban_headers, load_json_data, save_json_data, get_subject_info_with_cache, migrate_legacy_cache_data, load_subject_cache, is_cache_expired

# è·å–é…ç½®ç›®å½•
CONFIG_DIR = os.getenv('CONFIG_DIR', 'config')
CONFIG_FILE = os.path.join(CONFIG_DIR, 'config.json')
MOVIES_FILE = os.path.join(CONFIG_DIR, 'movies.json')



def parse_movie_item(item, cookie):
    """è§£æç”µå½±æ¡ç›®"""
    # è·å–æ ‡é¢˜
    title_elem = item.find('li', class_='title')
    if not title_elem or not title_elem.find('em'):
        return None
        
    # æ‹†åˆ†ä¸»æ ‡é¢˜å’Œå‰¯æ ‡é¢˜
    full_title = title_elem.find('em').text.strip()
    titles = full_title.split(' / ', 1)
    title = titles[0].strip()  # ä¸»æ ‡é¢˜
    subtitle = titles[1].strip() if len(titles) > 1 else ''  # å‰¯æ ‡é¢˜
    
    # è·å–é“¾æ¥å’ŒID
    url = ''
    link_elem = item.find('a', href=True)
    if link_elem:
        url = link_elem['href']
    
    # ä»URLä¸­æå–IDå¹¶è·å–ç±»å‹
    subject_id = extract_subject_id(url)
    if subject_id:
        print(f"å¤„ç†æ¡ç›®: {title} (ID: {subject_id})")
        info = get_subject_info_with_cache(subject_id, cookie)
        if info:
            media_type = info['type']
            imdb_id = info['imdb_id']
        else:
            print(f"è­¦å‘Š: æ— æ³•è·å–æ¡ç›®ä¿¡æ¯")
            media_type = 'movie'
            imdb_id = None
    else:
        print(f"è­¦å‘Š: æ— æ³•ä»URLæå–ID")
        media_type = 'movie'
        imdb_id = None
    
    # è·å–å…¶ä»–ä¿¡æ¯
    intro_elem = item.find('li', class_='intro')
    info = intro_elem.text.strip().split(' / ') if intro_elem else []
    
    date_elem = item.find('span', class_='date')
    date = date_elem.text.strip() if date_elem else ''
    
    img_elem = item.find('img')
    cover_url = img_elem.get('src', '') if img_elem else ''
    
    url = ''
    link_elem = item.find('a', href=True)
    if link_elem:
        url = link_elem['href']
    
    playable = bool(item.find('span', class_='playable'))
    
    subject_id = extract_subject_id(url)
    
    return {
        "title": title,
        "subtitle": subtitle,
        "full_title": full_title,
        "info": info,
        "date_added": date,
        "cover_url": cover_url,
        "url": url,
        "playable": playable,
        "type": media_type,
        "id": subject_id,
        "imdb_id": imdb_id
    }

def load_all_data():
    """åŠ è½½æ‰€æœ‰ç”¨æˆ·çš„æ•°æ®"""
    return load_json_data(MOVIES_FILE, {})

def save_all_data(all_data):
    """ä¿å­˜æ‰€æœ‰æ•°æ®åˆ°æ–‡ä»¶"""
    save_json_data(all_data, MOVIES_FILE)

def check_item_status(title, user_id, all_data):
    """æ£€æŸ¥æ¡ç›®çŠ¶æ€ï¼šæ–°å¢ã€é‡å¤ã€æˆ–éœ€è¦æ›´æ–°ç¼“å­˜
    
    è¿”å›å€¼:
        - ('new', None): å…¨æ–°æ¡ç›®
        - ('duplicate', item): é‡å¤æ¡ç›®ï¼Œç¼“å­˜æœªè¿‡æœŸ
        - ('cache_expired', item): é‡å¤æ¡ç›®ï¼Œä½†ç¼“å­˜å·²è¿‡æœŸï¼Œéœ€è¦æ›´æ–°
    """
    user_data = all_data.get(user_id, {'movies': [], 'tv_shows': []})
    all_items = user_data['movies'] + user_data['tv_shows']
    
    # åŒæ—¶æ£€æŸ¥ä¸»æ ‡é¢˜å’Œå®Œæ•´æ ‡é¢˜
    for item in all_items:
        if title == item.get('title') or title == item.get('full_title'):
            # æ‰¾åˆ°é‡å¤æ¡ç›®ï¼Œæ£€æŸ¥å…¶ç¼“å­˜æ˜¯å¦è¿‡æœŸ
            subject_id = item.get('id')
            if subject_id:
                # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
                cache_data = load_subject_cache()
                if subject_id in cache_data:
                    cached_at = cache_data[subject_id].get('cached_at')
                    if is_cache_expired(cached_at):
                        print(f"æ¡ç›® {title} ç¼“å­˜å·²è¿‡æœŸï¼Œå°†æ›´æ–°ä¿¡æ¯ï¼ˆä¸ä¼šå‘é€é€šçŸ¥ï¼‰")
                        return ('cache_expired', item)
                
            return ('duplicate', item)  # ç¼“å­˜æœªè¿‡æœŸæˆ–æ— ç¼“å­˜ä¿¡æ¯ï¼Œç®—ä½œé‡å¤
    
    return ('new', None)  # å…¨æ–°æ¡ç›®

def get_douban_html(user_id, cookie, list_type='wish', page=1):
    """è·å–è±†ç“£HTMLå†…å®¹
    
    list_type: åˆ—è¡¨ç±»å‹ï¼Œå¯é€‰å€¼ï¼š
    - wish: æƒ³çœ‹
    - do: åœ¨çœ‹
    - collect: å·²çœ‹
    page: é¡µç ï¼Œé»˜è®¤ä¸ºç¬¬1é¡µ
    """
    # è®¡ç®—èµ·å§‹ä½ç½®ï¼šæ¯é¡µ15ä¸ªæ¡ç›®
    start = (page - 1) * 15
    
    # æ ¹æ®åˆ—è¡¨ç±»å‹ç¡®å®šURL
    if list_type == 'do':
        url = f'https://movie.douban.com/people/{user_id}/do?start={start}&sort=time&rating=all&mode=grid&type=all&filter=all'
    elif list_type == 'collect':
        url = f'https://movie.douban.com/people/{user_id}/collect?start={start}&sort=time&rating=all&mode=grid&type=all&filter=all'
    else:  # é»˜è®¤ä¸ºwish
        url = f'https://movie.douban.com/people/{user_id}/wish?start={start}&sort=time&rating=all&mode=grid&type=all&filter=all'
        
    headers = make_douban_headers(cookie)
    
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        return response.text
    else:
        raise requests.RequestException(f"è·å–HTMLå¤±è´¥: HTTP {response.status_code}")

def fetch_user_data(user_id, cookie, user_config=None):
    """è·å–ç”¨æˆ·æ•°æ®"""
    try:
        print(f"å¤„ç†ç”¨æˆ· {user_id} çš„æ•°æ®...")
        user_note = user_config.get('note', '') if user_config else ''
        max_pages = user_config.get('pages', 1) if user_config else 1
        
        # ç¡®å®šéœ€è¦ç›‘æ§çš„åˆ—è¡¨ç±»å‹
        list_types = []
        if not user_config:
            # é»˜è®¤åªç›‘æ§æƒ³çœ‹åˆ—è¡¨
            list_types = ['wish']
        else:
            if user_config.get('monitor_wish', True):
                list_types.append('wish')
            if user_config.get('monitor_do'):
                list_types.append('do')
            if user_config.get('monitor_collect'):
                list_types.append('collect')
        
        all_data = load_all_data()
        has_updates = False
        
        print(f"ç”¨æˆ· {user_note or user_id} ç›‘æ§åˆ—è¡¨ç±»å‹: {', '.join(list_types)}ï¼ŒæŠ“å– {max_pages} é¡µ")
        
        for list_type in list_types:
            try:
                print(f"è·å– {list_type} åˆ—è¡¨æ•°æ®ä¸­...")
                
                # è·å–æ‰€æœ‰é¡µé¢çš„HTMLå†…å®¹
                all_html_content = ""
                for page in range(1, max_pages + 1):
                    print(f"  è·å–ç¬¬ {page}/{max_pages} é¡µ...")
                    
                    html_content = get_douban_html(user_id, cookie, list_type, page)
                    all_html_content += html_content
                    
                    # å¦‚æœä¸æ˜¯æœ€åä¸€é¡µï¼Œæ·»åŠ å»¶è¿Ÿ
                    if page < max_pages:
                        delay = random.uniform(1, 3)
                        print(f"  ç­‰å¾… {delay:.1f} ç§’åè·å–ä¸‹ä¸€é¡µ...")
                        time.sleep(delay)
                
                # ä¿å­˜åˆå¹¶åçš„HTMLå†…å®¹åˆ°æ–‡ä»¶ä½†ä¸è¾“å‡ºæç¤º
                html_file = f'douban_{user_id}_{list_type}.html'
                if os.path.exists(html_file):
                    os.remove(html_file)
                
                with open(html_file, 'w', encoding='utf-8') as f:
                    f.write(all_html_content)
                
                print(f"è§£æ {list_type} åˆ—è¡¨æ•°æ®ä¸­...")
                user_data = generate_movies_json(all_html_content, user_id, all_data, cookie, list_type)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ–°
                has_list_updates = user_data['new_items_count'] > 0
                has_updates = has_updates or has_list_updates
                
                # å¦‚æœè¿™ä¸ªåˆ—è¡¨æœ‰æ›´æ–°æ‰ä¿å­˜æ•°æ®
                if has_list_updates:
                    print(f"ç”¨æˆ· {user_id} çš„ {list_type} åˆ—è¡¨æœ‰æ›´æ–°: {user_data['new_items_count']} ä¸ªæ–°æ¡ç›®")
                else:
                    print(f"ç”¨æˆ· {user_id} çš„ {list_type} åˆ—è¡¨æ— å˜åŒ–")
                
                # æ·»åŠ ä¸€ä¸ªå»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                if list_type != list_types[-1]:
                    delay = random.uniform(1, 3)
                    print(f"ç­‰å¾… {delay:.1f} ç§’åç»§ç»­è·å–ä¸‹ä¸€ä¸ªåˆ—è¡¨...")
                    time.sleep(delay)
                    
            except Exception as e:
                print(f"å¤„ç†ç”¨æˆ· {user_id} çš„ {list_type} åˆ—è¡¨æ—¶å‡ºé”™: {e}")
        
        # æ›´æ–°ç”¨æˆ·æ•°æ®çš„æ ‡è®°
        user_data = all_data.get(user_id, {})
        user_data['has_updates'] = has_updates
        user_data['update_time'] = time.strftime('%Y-%m-%d %H:%M:%S')
        all_data[user_id] = user_data
        save_all_data(all_data)
        
        return has_updates
        
    except Exception as e:
        print(f"å¤„ç†ç”¨æˆ· {user_id} æ—¶å‡ºé”™: {e}")
        raise

def generate_movies_json(html_content, user_id, all_data, cookie, list_type='wish'):
    """è§£æHTMLå†…å®¹å¹¶ç”ŸæˆJSONæ•°æ®"""
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # è·å–æˆ–åˆå§‹åŒ–ç”¨æˆ·æ•°æ®
    user_data = all_data.get(user_id, {'movies': [], 'tv_shows': []})
    movies = user_data['movies']
    tv_shows = user_data['tv_shows']
    
    # æ‰¾åˆ°ç”µå½±åˆ—è¡¨å®¹å™¨
    items = soup.find_all('div', class_='item')
    total_items = len(items)
    new_items = 0
    
    print(f"å¼€å§‹å¤„ç† {list_type} åˆ—è¡¨ä¸­çš„ {total_items} ä¸ªæ¡ç›®...")
    
    for index, item in enumerate(items, 1):
        # è·å–æ ‡é¢˜
        title_elem = item.find('li', class_='title')
        if title_elem and title_elem.find('em'):
            full_title = title_elem.find('em').text.strip()
            titles = full_title.split(' / ', 1)
            title = titles[0].strip()
            
            # æ£€æŸ¥æ¡ç›®çŠ¶æ€
            status, existing_item = check_item_status(title, user_id, all_data)
            
            if status == 'duplicate':
                print(f"æ¡ç›®å·²å­˜åœ¨ï¼Œè·³è¿‡: {title}")
                continue
            elif status == 'cache_expired':
                # ç¼“å­˜è¿‡æœŸï¼Œéœ€è¦æ›´æ–°ä¿¡æ¯ä½†ä¸ç®—æ–°å¢
                print(f"å¤„ç†ç¼“å­˜è¿‡æœŸæ¡ç›® [{index}/{total_items}]: {title}")
                
                # è·å–æ›´æ–°åçš„ä¿¡æ¯
                data = parse_movie_item(item, cookie)
                
                # ä¿ç•™åŸæœ‰çš„notifiedçŠ¶æ€ï¼Œä¸æ”¹å˜é€šçŸ¥çŠ¶æ€
                data['notified'] = existing_item.get('notified', True)  # é»˜è®¤ä¸ºTrueï¼Œè¡¨ç¤ºä¸éœ€è¦é€šçŸ¥
                
                # æ·»åŠ æ¥æºæ ‡è®°
                data['source'] = list_type
                
                # ä»åŸåˆ—è¡¨ä¸­ç§»é™¤æ—§æ¡ç›®
                if existing_item in user_data['movies']:
                    user_data['movies'].remove(existing_item)
                elif existing_item in user_data['tv_shows']:
                    user_data['tv_shows'].remove(existing_item)
                
                # æ·»åŠ æ›´æ–°åçš„æ¡ç›®
                if data["type"] == "movie":
                    movies.append(data)
                    print(f"æ›´æ–°ç”µå½±ä¿¡æ¯: {data['title']} (æ¥è‡ª{list_type}åˆ—è¡¨)")
                else:
                    tv_shows.append(data)
                    print(f"æ›´æ–°å‰§é›†ä¿¡æ¯: {data['title']} (æ¥è‡ª{list_type}åˆ—è¡¨)")
                
                # å®æ—¶ä¿å­˜æ•°æ®
                all_data[user_id] = {'movies': movies, 'tv_shows': tv_shows}
                save_all_data(all_data)
                
                # ç¼“å­˜æ›´æ–°ä¸ç®—æ–°å¢ï¼Œä¸å¢åŠ new_itemsè®¡æ•°
                
            elif status == 'new':
                # å…¨æ–°æ¡ç›®
                print(f"å¤„ç†æ–°æ¡ç›® [{index}/{total_items}]: {title}")
                new_items += 1
                data = parse_movie_item(item, cookie)
                
                # è®¾ç½®notifiedä¸ºFalseï¼Œè¡¨ç¤ºè¿™æ˜¯ä¸€ä¸ªæ–°æ¡ç›®éœ€è¦é€šçŸ¥
                data['notified'] = False
                
                # æ·»åŠ æ¥æºæ ‡è®°ï¼Œæ–¹ä¾¿åç»­åŒºåˆ†æ•°æ®æ¥æº
                data['source'] = list_type
                
                # æ ¹æ®ç±»å‹æ·»åŠ åˆ°å¯¹åº”åˆ—è¡¨
                if data["type"] == "movie":
                    movies.append(data)
                    print(f"æ·»åŠ ç”µå½±: {data['title']} (æ¥è‡ª{list_type}åˆ—è¡¨)")
                else:
                    tv_shows.append(data)
                    print(f"æ·»åŠ å‰§é›†: {data['title']} (æ¥è‡ª{list_type}åˆ—è¡¨)")
                
                # å®æ—¶ä¿å­˜æ•°æ®
                all_data[user_id] = {'movies': movies, 'tv_shows': tv_shows}
                save_all_data(all_data)
            
            # åªåœ¨å¤„ç†æ–°æ¡ç›®æ—¶æ·»åŠ å»¶è¿Ÿ
            if index < total_items:
                delay = random.uniform(1, 3)
                print(f"ç­‰å¾… {delay:.1f} ç§’åç»§ç»­...")
                time.sleep(delay)
    
    print(f"{list_type}åˆ—è¡¨å¤„ç†å®Œæˆ! å‘ç° {new_items} ä¸ªæ–°æ¡ç›®ï¼Œå½“å‰ç”¨æˆ·å…±æœ‰ {len(movies)} éƒ¨ç”µå½±, {len(tv_shows)} éƒ¨ç”µè§†å‰§")
    
    # æ·»åŠ æ›´æ–°æ—¶é—´å’Œæ–°æ¡ç›®æ•°é‡
    result = {
        'movies': movies,
        'tv_shows': tv_shows,
        'update_time': time.strftime('%Y-%m-%d %H:%M:%S'),
        'new_items_count': new_items
    }
    
    return result

def cleanup_temp_files():
    """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
    try:
        # åˆ é™¤æ‰€æœ‰ douban_*.html æ–‡ä»¶
        for file in os.listdir():
            if file.startswith('douban_') and file.endswith('.html'):
                os.remove(file)
                print(f"å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {file}")
    except Exception as e:
        print(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶æ—¶å‡ºé”™: {e}")

def main():
    try:
        # åœ¨å¼€å§‹æ—¶è¿›è¡Œç¼“å­˜è¿ç§»
        print("æ£€æŸ¥å¹¶è¿ç§»æ—§ç¼“å­˜æ•°æ®...")
        migrate_legacy_cache_data()
        
        config = load_config()
        cookie = config.get('cookie', '')
        
        # éªŒè¯ cookie
        if not cookie:
            message = "âŒ Cookie æœªé…ç½®ï¼Œè¯·å…ˆé…ç½® Cookie"
            print(message)
            send_telegram_message(message, config, False)
            send_wecom_message(message, config, False)
            return
            
        if not check_cookie_valid(cookie):
            message = "âŒ Cookie å·²å¤±æ•ˆï¼Œè¯·æ›´æ–° Cookie"
            print(message)
            send_telegram_message(message, config, False)
            send_wecom_message(message, config, False)
            return
        
        print("å¼€å§‹è·å–è±†ç“£ç”¨æˆ·æ•°æ®...")
        
        # è®°å½•æ˜¯å¦æœ‰ä»»ä½•ç”¨æˆ·æ•°æ®æ›´æ–°
        any_updates = False
        # è·å–æ‰€æœ‰æ•°æ®
        all_data = load_all_data()
        
        # å¤„ç†æ¯ä¸ªç”¨æˆ·çš„æ•°æ®
        users = config.get('users', [])
        total_users = len(users)
        
        for i, user in enumerate(users, 1):
            user_id = user['id']
            note = user.get('note', '')
            try:
                print(f"[{i}/{total_users}] å¤„ç†ç”¨æˆ·: {note or user_id}")
                
                # è·å–æ›´æ–°ï¼Œä¼ å…¥å®Œæ•´çš„ç”¨æˆ·é…ç½®
                has_updates = fetch_user_data(user_id, cookie, user)
                
                if has_updates:
                    any_updates = True
                
                # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªç”¨æˆ·ï¼Œæ·»åŠ éšæœºå»¶è¿Ÿ
                if i < total_users:
                    delay = random.uniform(1, 3)  # 1-3ç§’çš„éšæœºå»¶è¿Ÿ
                    print(f"ç­‰å¾… {delay:.1f} ç§’åå¤„ç†ä¸‹ä¸€ä¸ªç”¨æˆ·...")
                    time.sleep(delay)
                    
            except Exception as e:
                print(f"å¤„ç†ç”¨æˆ· {user_id} æ—¶å‡ºé”™: {e}")
                continue
        
        # æ„å»ºæ¶ˆæ¯å†…å®¹ï¼Œä½†æ ¹æ®æƒ…å†µå†³å®šæ˜¯å¦å‘é€
        # æ— è®ºæ˜¯å¦æœ‰æ›´æ–°ï¼Œéƒ½æ„å»ºæ¶ˆæ¯
        message = "ğŸ¬ *è±†ç“£ç”µå½±/å‰§é›†æ›´æ–°æé†’*\n\n"
        
        # é‡æ–°åŠ è½½æ‰€æœ‰æ•°æ®ï¼Œç¡®ä¿è·å–æœ€æ–°çš„æ•°æ®
        all_data = load_all_data()
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœªé€šçŸ¥çš„æ¡ç›®
        has_unnotified_items = False
        for user_id, user_data in all_data.items():
            movies = user_data.get('movies', [])
            tv_shows = user_data.get('tv_shows', [])
            unnotified_items = [item for item in movies + tv_shows if not item.get('notified', False)]
            if unnotified_items:
                has_unnotified_items = True
                break
        
        if not has_unnotified_items:
            # æ²¡æœ‰æ–°å†…å®¹æ—¶çš„æ¶ˆæ¯
            message += "âš ï¸ æœ¬æ¬¡æ›´æ–°æ²¡æœ‰å‘ç°æ–°çš„å†…å®¹ã€‚\n\n"
        
        message += f"æ›´æ–°æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n"
        
        if has_unnotified_items:
            # æ•´ç†æ¯ä¸ªç”¨æˆ·çš„æœªé€šçŸ¥æ¡ç›®
            for user in users:
                user_id = user['id']
                note = user.get('note', '')
                user_data = all_data.get(user_id, {})
                movies = user_data.get('movies', [])
                tv_shows = user_data.get('tv_shows', [])
                
                # è·å–æœªé€šçŸ¥çš„æ¡ç›®
                unnotified_items = [item for item in movies + tv_shows if not item.get('notified', False)]
                
                if unnotified_items:
                    message += f"ç”¨æˆ· {note or user_id} æ–°å¢å†…å®¹:\n"
                    
                    # æŒ‰åˆ—è¡¨ç±»å‹åˆ†ç»„
                    items_by_source = {
                        'wish': [],
                        'do': [],
                        'collect': []
                    }
                    
                    # åˆ†ç»„
                    for item in unnotified_items:
                        source = item.get('source', 'wish')  # é»˜è®¤ä¸ºwish
                        items_by_source[source].append(item)
                        
                        # æ ‡è®°ä¸ºå·²é€šçŸ¥
                        item['notified'] = True
                    
                    # æŒ‰åˆ—è¡¨ç±»å‹æ˜¾ç¤º
                    source_names = {
                        'wish': 'æƒ³çœ‹',
                        'do': 'åœ¨çœ‹',
                        'collect': 'å·²çœ‹'
                    }
                    
                    for source, items in items_by_source.items():
                        if items:
                            message += f"â€¢ *{source_names.get(source, 'æœªçŸ¥')}*:\n"
                            for item in items:
                                # è·å–å¹´ä»½ä¿¡æ¯
                                year = item.get('year', '')
                                
                                # ä½¿ç”¨ä¸»æ ‡é¢˜å’Œå‰¯æ ‡é¢˜ï¼Œæ·»åŠ é“¾æ¥
                                url = item.get('url', f"https://movie.douban.com/subject/{item.get('id', '')}/")
                                message += f"  - <a href=\"{url}\">{item['title']}"
                                if item.get('subtitle'):
                                    message += f" ({item['subtitle']})"
                                if year:
                                    message += f" [{year}]"
                                message += "</a>\n"
                            
                    message += "\n"
            
            # ä¿å­˜æ›´æ–°åçš„æ•°æ®
            save_all_data(all_data)
        else:
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            total_movies = sum(len(user_data.get('movies', [])) for user_data in all_data.values())
            total_tv_shows = sum(len(user_data.get('tv_shows', [])) for user_data in all_data.values())
            
            message += f"å½“å‰æ€»è®¡è¿½è¸ª:\n"
            message += f"â€¢ {total_movies} éƒ¨ç”µå½±\n"
            message += f"â€¢ {total_tv_shows} éƒ¨å‰§é›†\n"
        
        # å‘é€é€šçŸ¥
        send_telegram_message(message, config, has_unnotified_items)
        send_wecom_message(message, config, has_unnotified_items)
        
        print("æ•°æ®è·å–å®Œæˆï¼")
        
    except Exception as e:
        error_message = f"âŒ è·å–è±†ç“£æ•°æ®æ—¶å‡ºé”™: {str(e)}"
        print(error_message)
        send_telegram_message(error_message, config, False)
        send_wecom_message(error_message, config, False)
    finally:
        # æ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        cleanup_temp_files()

if __name__ == "__main__":
    main() 