import json
import requests
from bs4 import BeautifulSoup
import time
import os
import re
import random
# å¯¼å…¥è±†ç“£å·¥å…·æ¨¡å—
from src.utils.douban_utils import extract_subject_id, load_config, check_cookie_valid, send_telegram_message, make_douban_headers, load_json_data, save_json_data, get_subject_info

# è·å–é…ç½®ç›®å½•
CONFIG_DIR = os.getenv('CONFIG_DIR', 'config')
CONFIG_FILE = os.path.join(CONFIG_DIR, 'config.json')
DOULIST_FILE = os.path.join(CONFIG_DIR, 'doulists.json')

def load_doulist_data():
    """åŠ è½½ç°æœ‰çš„ç‰‡å•æ•°æ®"""
    try:
        data = load_json_data(DOULIST_FILE, {"lists": {}, "update_time": ""})
        list_count = len(data.get("lists", {}))
        print(f"åŠ è½½è±†åˆ—æ•°æ®æˆåŠŸ: åŒ…å« {list_count} ä¸ªç‰‡å•")
        return data
    except Exception as e:
        print(f"åŠ è½½è±†åˆ—æ•°æ®å¤±è´¥: {e}")
        return {"lists": {}, "update_time": ""}

def save_doulist_data(data):
    """ä¿å­˜ç‰‡å•æ•°æ®"""
    try:
        if not data or not isinstance(data, dict):
            print(f"é”™è¯¯: ä¿å­˜çš„æ•°æ®æ ¼å¼ä¸æ­£ç¡®: {type(data)}")
            return False
            
        list_count = len(data.get("lists", {}))
        total_items = sum(len(doulist_data.get("items", [])) for doulist_id, doulist_data in data.get("lists", {}).items())
        
        save_json_data(data, DOULIST_FILE)
        print(f"è±†åˆ—æ•°æ®ä¿å­˜æˆåŠŸ: {list_count} ä¸ªç‰‡å•, {total_items} ä¸ªæ¡ç›®")
        return True
    except Exception as e:
        print(f"ä¿å­˜è±†åˆ—æ•°æ®å¤±è´¥: {e}")
        return False

def get_doulist_html(doulist_id, cookie, page=1):
    """è·å–ç‰‡å•HTMLå†…å®¹
    
    doulist_id: ç‰‡å•ID
    page: é¡µç ï¼Œé»˜è®¤ä¸ºç¬¬1é¡µ
    """
    # è®¡ç®—èµ·å§‹ä½ç½®ï¼šæ¯é¡µ25ä¸ªæ¡ç›®
    start = (page - 1) * 25
    
    # æŒ‰æ—¶é—´æ’åºï¼Œä½¿ç”¨startå‚æ•°è€Œä¸æ˜¯pageå‚æ•°
    url = f'https://www.douban.com/doulist/{doulist_id}/?start={start}&sort=time&playable=0&sub_type='
    headers = make_douban_headers(cookie)
    
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        return response.text
    else:
        raise requests.RequestException(f"è·å–ç‰‡å•HTMLå¤±è´¥: HTTP {response.status_code}")

def get_doulist_info(doulist_id, cookie):
    """è·å–ç‰‡å•åŸºæœ¬ä¿¡æ¯"""
    try:
        html_content = get_doulist_html(doulist_id, cookie)
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # è·å–ç‰‡å•æ ‡é¢˜
        title_elem = soup.find('h1')
        title = title_elem.text.strip() if title_elem else f"è±†åˆ— {doulist_id}"
        
        # è·å–ç‰‡å•æè¿°
        desc_elem = soup.find('div', class_='doulist-about')
        description = desc_elem.text.strip() if desc_elem else ""
        
        # è·å–ä½œè€…ä¿¡æ¯
        author_elem = soup.select_one('.doulist-owner a')
        author_name = author_elem.text.strip() if author_elem else ""
        author_url = author_elem['href'] if author_elem and 'href' in author_elem.attrs else ""
        author_id = ""
        if author_url:
            match = re.search(r'people/([^/]+)', author_url)
            if match:
                author_id = match.group(1)
        
        return {
            "id": doulist_id,
            "title": title,
            "description": description,
            "author": {
                "id": author_id,
                "name": author_name,
                "url": author_url
            },
            "url": f"https://www.douban.com/doulist/{doulist_id}/?start=0&sort=time&playable=0&sub_type="
        }
    except Exception as e:
        print(f"è·å–ç‰‡å•ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        return {
            "id": doulist_id,
            "title": f"è±†åˆ— {doulist_id}",
            "description": "",
            "author": {"id": "", "name": "", "url": ""},
            "url": f"https://www.douban.com/doulist/{doulist_id}/?start=0&sort=time&playable=0&sub_type="
        }

def is_movie_or_tv(item_url):
    """åˆ¤æ–­æ¡ç›®æ˜¯å¦ä¸ºç”µå½±/å‰§é›†"""
    return "movie.douban.com/subject/" in item_url

def parse_doulist_item(item, cookie):
    """è§£æç‰‡å•ä¸­çš„å•ä¸ªæ¡ç›®"""
    try:
        # è·å–é“¾æ¥å’Œæ ‡é¢˜
        title_elem = item.select_one('.title a')
        if not title_elem:
            return None
            
        url = title_elem.get('href', '')
        title = title_elem.text.strip()
        
        # è·³è¿‡éç”µå½±/å‰§é›†æ¡ç›®
        if not is_movie_or_tv(url):
            return None
            
        # è·å–å°é¢å›¾ç‰‡
        img_elem = item.select_one('.post img')
        cover_url = img_elem.get('src', '') if img_elem else ''
        
        # è·å–è¯„åˆ†
        rating_elem = item.select_one('.rating_nums')
        rating = rating_elem.text.strip() if rating_elem else "N/A"
        
        # è·å–æè¿°
        abstract_elem = item.select_one('.abstract')
        abstract = abstract_elem.text.strip() if abstract_elem else ""
        
        # ä»URLä¸­æå–ID
        subject_id = extract_subject_id(url)
        if not subject_id:
            return None
            
        # è·å–è¯¦ç»†ä¿¡æ¯ï¼Œä¸ä½¿ç”¨ç¼“å­˜ï¼Œæ¯æ¬¡éƒ½è·å–æœ€æ–°æ•°æ®
        print(f"è·å–è¯¦ç»†ä¿¡æ¯: {title} (ID: {subject_id})")
        info = get_subject_info(subject_id, cookie)
        
        if not info:
            print(f"æ— æ³•è·å–è¯¦ç»†ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            info = {
                'type': 'movie',  # é»˜è®¤ä¸ºç”µå½±
                'imdb_id': None,
                'year': '',
                'duration': '',
                'region': '',
                'director': [],
                'actors': [],
                'genres': [],
                'languages': [],
                'release_date': '',
                'vote_count': '',
                'episodes_info': {}
            }
            
        # æ„å»ºæ•°æ®ï¼Œæ·»åŠ æ›´å¤šå­—æ®µ
        result = {
            "id": subject_id,
            "title": title,
            "url": url,
            "cover_url": cover_url,
            "rating": rating,
            "intro": abstract,
            "type": info['type'],
            "imdb_id": info['imdb_id'],
            "year": info['year'],
            "director": info['director'],
            "actors": info['actors'],
            "genres": info['genres'],
            "region": info['region'],
            "languages": info['languages'],
            "duration": info['duration'],
            "release_date": info['release_date'],
            "vote_count": info['vote_count'],
            "notified": False,
            "add_time": time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # å¦‚æœæ˜¯ç”µè§†å‰§ï¼Œæ·»åŠ å‰§é›†ä¿¡æ¯
        if info['type'] == 'tv' and 'episodes_info' in info:
            result['episodes_info'] = info['episodes_info']
            
        return result
    except Exception as e:
        print(f"è§£æç‰‡å•æ¡ç›®å‡ºé”™: {e}")
        return None

def get_page_count(html_content):
    """è·å–ç‰‡å•çš„æ€»é¡µæ•°"""
    soup = BeautifulSoup(html_content, 'html.parser')
    paginator = soup.select_one('.paginator')
    if not paginator:
        return 1
        
    page_links = paginator.select('a')
    max_page = 1
    
    for link in page_links:
        try:
            page_num = int(link.text.strip())
            max_page = max(max_page, page_num)
        except ValueError:
            continue
            
    return max_page

def is_duplicate(subject_id, doulist_id, all_data):
    """æ£€æŸ¥æ¡ç›®æ˜¯å¦å·²å­˜åœ¨ï¼ˆäºŒæ¬¡ç¡®è®¤ï¼‰
    
    è¯¥å‡½æ•°ç”¨äºåœ¨ä¿å­˜å‰å†æ¬¡ç¡®è®¤IDæ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…ç«æ€æ¡ä»¶
    """
    if doulist_id not in all_data["lists"]:
        return False
        
    existing_items = all_data["lists"][doulist_id].get("items", [])
    
    for item in existing_items:
        if item.get("id") == subject_id:
            return True
            
    return False

def fetch_doulist(doulist_id, cookie, max_pages=5):
    """è·å–ç‰‡å•ä¸­çš„æ‰€æœ‰æ¡ç›®
    
    doulist_id: ç‰‡å•ID
    max_pages: æœ€å¤§è·å–é¡µæ•°ï¼Œé»˜è®¤ä¸º5é¡µ
    """
    try:
        print(f"å¼€å§‹è·å–ç‰‡å• {doulist_id} æ•°æ®...")
        all_data = load_doulist_data()
        
        # åˆå§‹åŒ–åˆ—è¡¨ï¼Œå¦‚æœæ˜¯æ–°ç‰‡å•ï¼Œéœ€è¦åˆ›å»ºç»“æ„
        if doulist_id not in all_data["lists"]:
            print(f"ç‰‡å• {doulist_id} ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°ç»“æ„")
            all_data["lists"][doulist_id] = {
                "items": [],
                "update_time": time.strftime('%Y-%m-%d %H:%M:%S'),
                "has_update": False
            }
            save_doulist_data(all_data)
        else:
            items_count = len(all_data["lists"][doulist_id].get("items", []))
            print(f"ç‰‡å• {doulist_id} å·²å­˜åœ¨ï¼Œå½“å‰æœ‰ {items_count} ä¸ªæ¡ç›®")
        
        # å‡†å¤‡ä¸€ä¸ªç°æœ‰æ¡ç›®IDçš„é›†åˆï¼Œç”¨äºå¿«é€ŸæŸ¥æ‰¾
        existing_ids = set()
        if doulist_id in all_data["lists"]:
            existing_ids = {item.get("id") for item in all_data["lists"][doulist_id].get("items", [])}
            print(f"å½“å‰ç‰‡å•å·²æœ‰ {len(existing_ids)} ä¸ªå”¯ä¸€æ¡ç›®ID")
        
        # è·å–ç¬¬ä¸€é¡µå¹¶è§£ææ€»é¡µæ•°
        first_page_html = get_doulist_html(doulist_id, cookie)
        total_pages = min(get_page_count(first_page_html), max_pages)
        
        print(f"ç‰‡å•å…±æœ‰ {total_pages} é¡µï¼Œå°†è·å–æœ€å¤š {max_pages} é¡µ")
        
        # è·å–ç‰‡å•åŸºæœ¬ä¿¡æ¯
        list_info = get_doulist_info(doulist_id, cookie)
        all_data = load_doulist_data()
        all_data["lists"][doulist_id]["list_info"] = list_info
        print(f"æ›´æ–°ç‰‡å•åŸºæœ¬ä¿¡æ¯: {list_info.get('title', 'æœªçŸ¥')}")
        save_doulist_data(all_data)
        
        # è®°å½•æ–°æ¡ç›®å’Œè®¡æ•°
        new_items = []
        new_items_count = 0
        
        # å¤„ç†æ‰€æœ‰é¡µé¢
        for page in range(1, total_pages + 1):
            try:
                if page > 1:
                    print(f"\nè·å–ç¬¬ {page}/{total_pages} é¡µ...")
                    page_html = get_doulist_html(doulist_id, cookie, page)
                    soup = BeautifulSoup(page_html, 'html.parser')
                else:
                    print(f"\nå¤„ç†ç¬¬1é¡µ...")
                    soup = BeautifulSoup(first_page_html, 'html.parser')
                
                items = soup.select('.doulist-item')
                print(f"ç¬¬{page}é¡µæ‰¾åˆ° {len(items)} ä¸ªæ¡ç›®")
                
                # å¤„ç†é¡µé¢ä¸Šçš„æ‰€æœ‰æ¡ç›®
                for idx, html_item in enumerate(items, 1):
                    try:
                        # å…ˆè·å–æ ‡é¢˜å’Œé“¾æ¥ï¼Œæå–ID
                        title_elem = html_item.select_one('.title a')
                        if not title_elem:
                            continue
                        
                        url = title_elem.get('href', '')
                        title = title_elem.text.strip()
                        
                        # è·³è¿‡éç”µå½±/å‰§é›†æ¡ç›®
                        if not is_movie_or_tv(url):
                            continue
                        
                        # ä»URLä¸­æå–ID
                        subject_id = extract_subject_id(url)
                        if not subject_id:
                            continue
                        
                        # æ£€æŸ¥è¯¥IDæ˜¯å¦å·²å­˜åœ¨
                        if subject_id in existing_ids:
                            print(f"[{page}é¡µ-{idx}] è·³è¿‡å·²å­˜åœ¨æ¡ç›®: {title} (ID: {subject_id})")
                            continue
                        
                        # åªæœ‰æ–°æ¡ç›®æ‰è·å–è¯¦ç»†ä¿¡æ¯
                        print(f"[{page}é¡µ-{idx}] å‘ç°æ–°æ¡ç›®: {title} (ID: {subject_id})")
                        item = parse_doulist_item(html_item, cookie)
                        if not item:
                            continue
                        
                        # æ¯æ¬¡å¤„ç†æ–°æ¡ç›®æ—¶éƒ½é‡æ–°åŠ è½½æ•°æ®
                        current_data = load_doulist_data()
                        
                        # å†æ¬¡æ£€æŸ¥æ˜¯å¦é‡å¤ï¼ˆä»¥é˜²ä¸‡ä¸€å…¶ä»–è¿›ç¨‹å·²æ·»åŠ ï¼‰
                        if is_duplicate(item["id"], doulist_id, current_data):
                            continue
                        
                        # æ·»åŠ åˆ°åˆ—è¡¨å¤´éƒ¨
                        current_data["lists"][doulist_id]["items"].insert(0, item)
                        current_data["lists"][doulist_id]["update_time"] = time.strftime('%Y-%m-%d %H:%M:%S')
                        current_data["lists"][doulist_id]["has_update"] = True
                        
                        # ç«‹å³ä¿å­˜
                        print(f"ä¿å­˜æ–°æ¡ç›®: {item['title']}")
                        save_doulist_data(current_data)
                        
                        # æ·»åŠ åˆ°æ–°IDé›†åˆ
                        existing_ids.add(subject_id)
                        new_items.append(item)
                        new_items_count += 1
                        
                    except Exception as e:
                        print(f"å¤„ç†æ¡ç›®æ—¶å‡ºé”™: {e}")
                        continue
                    
                    # å¤„ç†å®Œä¸€ä¸ªæ¡ç›®åæ·»åŠ å»¶è¿Ÿ
                    if idx < len(items):
                        delay = random.uniform(0.5, 1.5)
                        time.sleep(delay)
                
                # æ·»åŠ é¡µé¢é—´éšæœºå»¶è¿Ÿ
                if page < total_pages:
                    delay = random.uniform(2, 5)
                    print(f"ç­‰å¾… {delay:.1f} ç§’åè·å–ä¸‹ä¸€é¡µ...")
                    time.sleep(delay)
                    
            except Exception as e:
                print(f"è·å–æˆ–è§£æç¬¬ {page} é¡µæ—¶å‡ºé”™: {e}")
                continue
        
        # æ›´æ–°å…¨å±€æ›´æ–°æ—¶é—´
        print("\næ‰€æœ‰é¡µé¢å¤„ç†å®Œæˆï¼Œæ›´æ–°æ—¶é—´æˆ³")
        final_data = load_doulist_data()
        final_data["update_time"] = time.strftime('%Y-%m-%d %H:%M:%S')
        save_doulist_data(final_data)
        
        print(f"ç‰‡å• {doulist_id} å¤„ç†å®Œæˆï¼Œå…±æ–°å¢ {new_items_count} ä¸ªæ¡ç›®")
        
        return {
            "success": True,
            "list_info": list_info,
            "new_items": new_items,
            "new_items_count": new_items_count,
            "update_time": time.strftime('%Y-%m-%d %H:%M:%S'),
            "has_update": new_items_count > 0
        }
    except Exception as e:
        print(f"è·å–ç‰‡å• {doulist_id} æ•°æ®æ—¶å‡ºé”™: {e}")
        return {
            "success": False,
            "error": str(e)
        }

def update_doulist(doulist_id, doulist_config, cookie):
    """æ›´æ–°æŒ‡å®šç‰‡å•çš„æ•°æ®"""
    # è·å–é…ç½®
    max_pages = doulist_config.get("pages", 5)
    note = doulist_config.get("note", "")
    
    print(f"æ›´æ–°ç‰‡å• {note or doulist_id}ï¼Œè·å– {max_pages} é¡µ...")
    
    try:
        # è·å–ç‰‡å•æ•°æ®
        result = fetch_doulist(doulist_id, cookie, max_pages)
        
        if result["success"]:
            # åŠ è½½æœ€æ–°æ•°æ®
            all_data = load_doulist_data()
            
            # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡æ·»åŠ è¯¥ç‰‡å•ï¼Œä¿å­˜é…ç½®ä¿¡æ¯
            if "config" not in all_data["lists"].get(doulist_id, {}):
                all_data["lists"][doulist_id]["config"] = {
                    "note": note,
                    "pages": max_pages
                }
                save_doulist_data(all_data)
            
            new_items_count = result["new_items_count"]
            
            if new_items_count > 0:
                print(f"ç‰‡å• {note or doulist_id} æˆåŠŸæ·»åŠ  {new_items_count} ä¸ªæ–°æ¡ç›®")
            else:
                print(f"ç‰‡å• {note or doulist_id} æ²¡æœ‰æ–°æ¡ç›®")
                
            # è·å–å½“å‰æ€»æ¡ç›®æ•°
            total_items = len(all_data["lists"][doulist_id]["items"])
            
            return {
                "success": True,
                "new_items_count": new_items_count,
                "total_items": total_items
            }
        else:
            return {
                "success": False,
                "error": result.get("error", "è·å–ç‰‡å•æ•°æ®å¤±è´¥")
            }
    except Exception as e:
        print(f"æ›´æ–°ç‰‡å• {doulist_id} æ—¶å‡ºé”™: {e}")
        return {
            "success": False,
            "error": str(e)
        }

def main():
    try:
        config = load_config()
        cookie = config.get('cookie', '')
        
        # éªŒè¯ cookie
        if not cookie:
            message = "âŒ Cookie æœªé…ç½®ï¼Œè¯·å…ˆé…ç½® Cookie"
            print(message)
            send_telegram_message(message, config, False)
            return
            
        if not check_cookie_valid(cookie):
            message = "âŒ Cookie å·²å¤±æ•ˆï¼Œè¯·æ›´æ–° Cookie"
            print(message)
            send_telegram_message(message, config, False)
            return
        
        print("\n======= å¼€å§‹è±†ç“£ç‰‡å•æŠ“å–ä»»åŠ¡ =======")
        
        # è·å–ç‰‡å•é…ç½®
        doulists = config.get('doulists', [])
        if not doulists:
            print("æ²¡æœ‰é…ç½®ç‰‡å•ï¼Œè·³è¿‡")
            return
            
        # è®°å½•æ˜¯å¦æœ‰ä»»ä½•ç‰‡å•æ›´æ–°
        any_updates = False
        new_items_total = 0
        new_items_by_list = {}
        
        # å¤„ç†æ¯ä¸ªç‰‡å•
        total_lists = len(doulists)
        print(f"å…±æœ‰ {total_lists} ä¸ªç‰‡å•éœ€è¦å¤„ç†")
        
        for i, doulist_config in enumerate(doulists, 1):
            doulist_id = doulist_config.get('id')
            note = doulist_config.get('note', '')
            
            if not doulist_id:
                print(f"[{i}/{total_lists}] ç‰‡å•IDä¸ºç©ºï¼Œè·³è¿‡")
                continue
                
            try:
                print(f"\n---------- å¤„ç†ç‰‡å• {i}/{total_lists}: {note or doulist_id} ----------")
                
                # æ›´æ–°ç‰‡å•æ•°æ®
                result = update_doulist(doulist_id, doulist_config, cookie)
                
                if result["success"]:
                    print(f"ç‰‡å• {note or doulist_id} å¤„ç†ç»“æœ: æˆåŠŸ")
                    print(f"  - æ–°å¢æ¡ç›®: {result['new_items_count']}")
                    print(f"  - æ€»æ¡ç›®æ•°: {result['total_items']}")
                    
                    if result["new_items_count"] > 0:
                        any_updates = True
                        new_items_total += result["new_items_count"]
                        new_items_by_list[doulist_id] = {
                            "count": result["new_items_count"],
                            "note": note
                        }
                else:
                    print(f"ç‰‡å• {note or doulist_id} å¤„ç†ç»“æœ: å¤±è´¥")
                    print(f"  - é”™è¯¯ä¿¡æ¯: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
                # æ·»åŠ éšæœºå»¶è¿Ÿ
                if i < total_lists:
                    delay = random.uniform(3, 6)
                    print(f"\nç­‰å¾… {delay:.1f} ç§’åå¤„ç†ä¸‹ä¸€ä¸ªç‰‡å•...")
                    time.sleep(delay)
            except Exception as e:
                print(f"å¤„ç†ç‰‡å• {doulist_id} æ—¶å‡ºé”™: {e}")
                continue
        
        print("\n===== æ‰€æœ‰ç‰‡å•å¤„ç†å®Œæˆ =====")
        print(f"æ€»ç»“: å…±å¤„ç† {total_lists} ä¸ªç‰‡å•ï¼Œæœ‰ {len(new_items_by_list)} ä¸ªç‰‡å•æœ‰æ›´æ–°ï¼Œå…± {new_items_total} ä¸ªæ–°æ¡ç›®")
        
        # æ„å»ºé€šçŸ¥æ¶ˆæ¯
        if any_updates:
            # æœ‰æ›´æ–°æ—¶çš„æ¶ˆæ¯
            message = "ğŸ“‹ <b>è±†ç“£ç‰‡å•æ›´æ–°æé†’</b>\n\n"
            
            # åŠ è½½æœ€æ–°æ•°æ®
            print("\næ­£åœ¨æ„å»ºé€šçŸ¥æ¶ˆæ¯...")
            all_data = load_doulist_data()
            
            # æ·»åŠ æ–°å†…å®¹æ‘˜è¦
            for doulist_id, info in new_items_by_list.items():
                list_data = all_data["lists"].get(doulist_id, {})
                list_info = list_data.get("list_info", {})
                list_title = list_info.get("title", f"è±†åˆ— {doulist_id}")
                list_url = list_info.get("url", f"https://www.douban.com/doulist/{doulist_id}/?start=0&sort=time&playable=0&sub_type=")
                
                message += f"<b><a href='{list_url}'>{list_title}</a></b> æ–°å¢ {info['count']} éƒ¨ä½œå“:\n"
                
                # è·å–æœªé€šçŸ¥çš„æ¡ç›®
                new_items = [item for item in list_data.get("items", []) if not item.get("notified", True)][:100]  # æœ€å¤šæ˜¾ç¤º100ä¸ª
                
                for item in new_items:
                    title = item.get("title", "")
                    url = item.get("url", "")
                    rating = item.get("rating", "N/A")
                    
                    message += f"â€¢ <a href='{url}'>{title}</a> - â­{rating}\n"
                    
                    # æ ‡è®°ä¸ºå·²é€šçŸ¥
                    item["notified"] = True
                
                # å¦‚æœæ–°å¢è¶…è¿‡100ä¸ªï¼Œæ·»åŠ "ç­‰"å­—æ ·
                if info["count"] > 100:
                    message += f"ç­‰ {info['count']} éƒ¨ä½œå“\n"
                    
                message += "\n"
            
            # ä¿å­˜æ›´æ–°åçš„æ•°æ®ï¼ˆå·²æ ‡è®°é€šçŸ¥çŠ¶æ€ï¼‰
            print("ä¿å­˜å·²é€šçŸ¥çŠ¶æ€...")
            save_doulist_data(all_data)
            
            # å‘é€é€šçŸ¥
            print("å‘é€é€šçŸ¥æ¶ˆæ¯...")
            try:
                send_telegram_message(message, config, True)
                print("é€šçŸ¥æ¶ˆæ¯å‘é€æˆåŠŸ")
            except Exception as e:
                print(f"å‘é€é€šçŸ¥æ¶ˆæ¯å¤±è´¥: {e}")
            
            print(f"\nç‰‡å•æ•°æ®æ›´æ–°å®Œæˆï¼å…±æœ‰ {new_items_total} ä¸ªæ–°æ¡ç›®")
        else:
            print("\nç‰‡å•æ•°æ®æ›´æ–°å®Œæˆï¼æ²¡æœ‰æ–°å†…å®¹")
            
            # å¯é€‰ï¼šå‘é€æ— æ›´æ–°é€šçŸ¥
            if config.get('telegram', {}).get('notify_mode') != 'new_only':
                message = "ğŸ“‹ <b>è±†ç“£ç‰‡å•æ›´æ–°æé†’</b>\n\n"
                message += "âš ï¸ æœ¬æ¬¡æ›´æ–°æ²¡æœ‰å‘ç°æ–°çš„å†…å®¹ã€‚\n\n"
                message += f"æ›´æ–°æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n"
                
                try:
                    send_telegram_message(message, config, False)
                    print("é€šçŸ¥æ¶ˆæ¯å‘é€æˆåŠŸ")
                except Exception as e:
                    print(f"å‘é€é€šçŸ¥æ¶ˆæ¯å¤±è´¥: {e}")
    
    except Exception as e:
        error_message = f"âŒ è·å–è±†ç“£ç‰‡å•æ•°æ®æ—¶å‡ºé”™: {str(e)}"
        print(error_message)
        try:
            config = load_config()
            send_telegram_message(error_message, config, False)
        except Exception as send_err:
            print(f"å‘é€é”™è¯¯é€šçŸ¥å¤±è´¥: {send_err}")
    
    print("\n======= ç‰‡å•æŠ“å–ä»»åŠ¡ç»“æŸ =======\n")

if __name__ == "__main__":
    main() 